{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 2000,
  "global_step": 2013,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014903129657228018,
      "grad_norm": 1.5974100828170776,
      "learning_rate": 4.950495049504951e-06,
      "loss": 0.1931,
      "step": 10
    },
    {
      "epoch": 0.029806259314456036,
      "grad_norm": 1.6589232683181763,
      "learning_rate": 9.900990099009901e-06,
      "loss": 0.2043,
      "step": 20
    },
    {
      "epoch": 0.044709388971684055,
      "grad_norm": 2.042121171951294,
      "learning_rate": 1.4851485148514851e-05,
      "loss": 0.2117,
      "step": 30
    },
    {
      "epoch": 0.05961251862891207,
      "grad_norm": 1.4272123575210571,
      "learning_rate": 1.9801980198019803e-05,
      "loss": 0.1889,
      "step": 40
    },
    {
      "epoch": 0.07451564828614009,
      "grad_norm": 1.952551007270813,
      "learning_rate": 2.4752475247524754e-05,
      "loss": 0.2001,
      "step": 50
    },
    {
      "epoch": 0.08941877794336811,
      "grad_norm": 1.6141422986984253,
      "learning_rate": 2.9702970297029702e-05,
      "loss": 0.1936,
      "step": 60
    },
    {
      "epoch": 0.10432190760059612,
      "grad_norm": 2.4117860794067383,
      "learning_rate": 3.465346534653465e-05,
      "loss": 0.1756,
      "step": 70
    },
    {
      "epoch": 0.11922503725782414,
      "grad_norm": 2.557743787765503,
      "learning_rate": 3.9603960396039605e-05,
      "loss": 0.1896,
      "step": 80
    },
    {
      "epoch": 0.13412816691505217,
      "grad_norm": 2.875722646713257,
      "learning_rate": 4.455445544554456e-05,
      "loss": 0.1925,
      "step": 90
    },
    {
      "epoch": 0.14903129657228018,
      "grad_norm": 1.915502667427063,
      "learning_rate": 4.950495049504951e-05,
      "loss": 0.1892,
      "step": 100
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 1.7600125074386597,
      "learning_rate": 5.445544554455446e-05,
      "loss": 0.1789,
      "step": 110
    },
    {
      "epoch": 0.17883755588673622,
      "grad_norm": 2.674158811569214,
      "learning_rate": 5.9405940594059404e-05,
      "loss": 0.1863,
      "step": 120
    },
    {
      "epoch": 0.19374068554396423,
      "grad_norm": 1.9055300951004028,
      "learning_rate": 6.435643564356436e-05,
      "loss": 0.185,
      "step": 130
    },
    {
      "epoch": 0.20864381520119224,
      "grad_norm": 1.7747834920883179,
      "learning_rate": 6.93069306930693e-05,
      "loss": 0.1549,
      "step": 140
    },
    {
      "epoch": 0.22354694485842028,
      "grad_norm": 1.6319750547409058,
      "learning_rate": 7.425742574257426e-05,
      "loss": 0.1841,
      "step": 150
    },
    {
      "epoch": 0.23845007451564829,
      "grad_norm": 3.0592942237854004,
      "learning_rate": 7.920792079207921e-05,
      "loss": 0.1735,
      "step": 160
    },
    {
      "epoch": 0.2533532041728763,
      "grad_norm": 2.035966157913208,
      "learning_rate": 8.415841584158417e-05,
      "loss": 0.1914,
      "step": 170
    },
    {
      "epoch": 0.26825633383010433,
      "grad_norm": 2.5523641109466553,
      "learning_rate": 8.910891089108912e-05,
      "loss": 0.1896,
      "step": 180
    },
    {
      "epoch": 0.28315946348733234,
      "grad_norm": 1.9913527965545654,
      "learning_rate": 9.405940594059406e-05,
      "loss": 0.1945,
      "step": 190
    },
    {
      "epoch": 0.29806259314456035,
      "grad_norm": 2.0267539024353027,
      "learning_rate": 9.900990099009902e-05,
      "loss": 0.1888,
      "step": 200
    },
    {
      "epoch": 0.31296572280178836,
      "grad_norm": 2.092247247695923,
      "learning_rate": 9.99951852265483e-05,
      "loss": 0.1887,
      "step": 210
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 1.3147565126419067,
      "learning_rate": 9.997562679862767e-05,
      "loss": 0.2179,
      "step": 220
    },
    {
      "epoch": 0.34277198211624443,
      "grad_norm": 2.0396599769592285,
      "learning_rate": 9.994102967390383e-05,
      "loss": 0.2007,
      "step": 230
    },
    {
      "epoch": 0.35767511177347244,
      "grad_norm": 1.888891339302063,
      "learning_rate": 9.98914042633652e-05,
      "loss": 0.2063,
      "step": 240
    },
    {
      "epoch": 0.37257824143070045,
      "grad_norm": 2.1006979942321777,
      "learning_rate": 9.982676550032123e-05,
      "loss": 0.2064,
      "step": 250
    },
    {
      "epoch": 0.38748137108792846,
      "grad_norm": 1.9525507688522339,
      "learning_rate": 9.974713283590886e-05,
      "loss": 0.1735,
      "step": 260
    },
    {
      "epoch": 0.40238450074515647,
      "grad_norm": 2.0558876991271973,
      "learning_rate": 9.965253023323915e-05,
      "loss": 0.1879,
      "step": 270
    },
    {
      "epoch": 0.4172876304023845,
      "grad_norm": 2.320955991744995,
      "learning_rate": 9.954298616018634e-05,
      "loss": 0.1918,
      "step": 280
    },
    {
      "epoch": 0.43219076005961254,
      "grad_norm": 2.273613929748535,
      "learning_rate": 9.941853358082124e-05,
      "loss": 0.1855,
      "step": 290
    },
    {
      "epoch": 0.44709388971684055,
      "grad_norm": 1.9594379663467407,
      "learning_rate": 9.927920994549172e-05,
      "loss": 0.1965,
      "step": 300
    },
    {
      "epoch": 0.46199701937406856,
      "grad_norm": 2.4099009037017822,
      "learning_rate": 9.912505717955303e-05,
      "loss": 0.2097,
      "step": 310
    },
    {
      "epoch": 0.47690014903129657,
      "grad_norm": 1.6861480474472046,
      "learning_rate": 9.895612167075173e-05,
      "loss": 0.2118,
      "step": 320
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 1.776662826538086,
      "learning_rate": 9.877245425526654e-05,
      "loss": 0.1829,
      "step": 330
    },
    {
      "epoch": 0.5067064083457526,
      "grad_norm": 2.7360403537750244,
      "learning_rate": 9.857411020241072e-05,
      "loss": 0.1957,
      "step": 340
    },
    {
      "epoch": 0.5216095380029806,
      "grad_norm": 2.551331043243408,
      "learning_rate": 9.836114919800047e-05,
      "loss": 0.1811,
      "step": 350
    },
    {
      "epoch": 0.5365126676602087,
      "grad_norm": 2.0750460624694824,
      "learning_rate": 9.813363532639412e-05,
      "loss": 0.1972,
      "step": 360
    },
    {
      "epoch": 0.5514157973174366,
      "grad_norm": 1.8112332820892334,
      "learning_rate": 9.789163705120789e-05,
      "loss": 0.1878,
      "step": 370
    },
    {
      "epoch": 0.5663189269746647,
      "grad_norm": 1.9661650657653809,
      "learning_rate": 9.763522719471375e-05,
      "loss": 0.1761,
      "step": 380
    },
    {
      "epoch": 0.5812220566318927,
      "grad_norm": 1.4385631084442139,
      "learning_rate": 9.736448291592575e-05,
      "loss": 0.1838,
      "step": 390
    },
    {
      "epoch": 0.5961251862891207,
      "grad_norm": 2.3440308570861816,
      "learning_rate": 9.70794856873812e-05,
      "loss": 0.1784,
      "step": 400
    },
    {
      "epoch": 0.6110283159463488,
      "grad_norm": 1.5225886106491089,
      "learning_rate": 9.678032127062401e-05,
      "loss": 0.2084,
      "step": 410
    },
    {
      "epoch": 0.6259314456035767,
      "grad_norm": 3.3761725425720215,
      "learning_rate": 9.64670796903971e-05,
      "loss": 0.1838,
      "step": 420
    },
    {
      "epoch": 0.6408345752608048,
      "grad_norm": 2.1573846340179443,
      "learning_rate": 9.613985520755231e-05,
      "loss": 0.1815,
      "step": 430
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 2.933053970336914,
      "learning_rate": 9.57987462906852e-05,
      "loss": 0.1891,
      "step": 440
    },
    {
      "epoch": 0.6706408345752608,
      "grad_norm": 1.7619246244430542,
      "learning_rate": 9.54438555865039e-05,
      "loss": 0.1727,
      "step": 450
    },
    {
      "epoch": 0.6855439642324889,
      "grad_norm": 1.9463036060333252,
      "learning_rate": 9.507528988894058e-05,
      "loss": 0.1926,
      "step": 460
    },
    {
      "epoch": 0.7004470938897168,
      "grad_norm": 1.820799708366394,
      "learning_rate": 9.469316010701496e-05,
      "loss": 0.1847,
      "step": 470
    },
    {
      "epoch": 0.7153502235469449,
      "grad_norm": 1.6473573446273804,
      "learning_rate": 9.429758123145948e-05,
      "loss": 0.1776,
      "step": 480
    },
    {
      "epoch": 0.7302533532041728,
      "grad_norm": 3.096966505050659,
      "learning_rate": 9.388867230011625e-05,
      "loss": 0.2036,
      "step": 490
    },
    {
      "epoch": 0.7451564828614009,
      "grad_norm": 1.213444709777832,
      "learning_rate": 9.346655636211601e-05,
      "loss": 0.2139,
      "step": 500
    },
    {
      "epoch": 0.7600596125186289,
      "grad_norm": 2.543811082839966,
      "learning_rate": 9.30313604408503e-05,
      "loss": 0.2137,
      "step": 510
    },
    {
      "epoch": 0.7749627421758569,
      "grad_norm": 3.137972116470337,
      "learning_rate": 9.258321549574731e-05,
      "loss": 0.1806,
      "step": 520
    },
    {
      "epoch": 0.789865871833085,
      "grad_norm": 1.9042261838912964,
      "learning_rate": 9.212225638286356e-05,
      "loss": 0.1773,
      "step": 530
    },
    {
      "epoch": 0.8047690014903129,
      "grad_norm": 1.954579472541809,
      "learning_rate": 9.1648621814303e-05,
      "loss": 0.209,
      "step": 540
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 1.8675405979156494,
      "learning_rate": 9.116245431647552e-05,
      "loss": 0.1719,
      "step": 550
    },
    {
      "epoch": 0.834575260804769,
      "grad_norm": 2.5706162452697754,
      "learning_rate": 9.0663900187208e-05,
      "loss": 0.2006,
      "step": 560
    },
    {
      "epoch": 0.849478390461997,
      "grad_norm": 2.114563465118408,
      "learning_rate": 9.015310945172011e-05,
      "loss": 0.1852,
      "step": 570
    },
    {
      "epoch": 0.8643815201192251,
      "grad_norm": 2.581623077392578,
      "learning_rate": 8.963023581747874e-05,
      "loss": 0.2095,
      "step": 580
    },
    {
      "epoch": 0.879284649776453,
      "grad_norm": 1.8162990808486938,
      "learning_rate": 8.90954366279442e-05,
      "loss": 0.1804,
      "step": 590
    },
    {
      "epoch": 0.8941877794336811,
      "grad_norm": 2.287428617477417,
      "learning_rate": 8.854887281522233e-05,
      "loss": 0.1916,
      "step": 600
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 2.192432165145874,
      "learning_rate": 8.799070885163676e-05,
      "loss": 0.1853,
      "step": 610
    },
    {
      "epoch": 0.9239940387481371,
      "grad_norm": 1.7935261726379395,
      "learning_rate": 8.74211127002357e-05,
      "loss": 0.226,
      "step": 620
    },
    {
      "epoch": 0.9388971684053651,
      "grad_norm": 2.1331429481506348,
      "learning_rate": 8.684025576424853e-05,
      "loss": 0.2075,
      "step": 630
    },
    {
      "epoch": 0.9538002980625931,
      "grad_norm": 1.913595199584961,
      "learning_rate": 8.624831283550684e-05,
      "loss": 0.2089,
      "step": 640
    },
    {
      "epoch": 0.9687034277198212,
      "grad_norm": 1.5695692300796509,
      "learning_rate": 8.56454620418462e-05,
      "loss": 0.196,
      "step": 650
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 2.4697749614715576,
      "learning_rate": 8.503188479350361e-05,
      "loss": 0.1811,
      "step": 660
    },
    {
      "epoch": 0.9985096870342772,
      "grad_norm": 2.2048535346984863,
      "learning_rate": 8.440776572852756e-05,
      "loss": 0.1891,
      "step": 670
    },
    {
      "epoch": 1.0134128166915053,
      "grad_norm": 2.213169574737549,
      "learning_rate": 8.377329265721656e-05,
      "loss": 0.1165,
      "step": 680
    },
    {
      "epoch": 1.0283159463487332,
      "grad_norm": 3.808969259262085,
      "learning_rate": 8.312865650560316e-05,
      "loss": 0.0789,
      "step": 690
    },
    {
      "epoch": 1.0432190760059612,
      "grad_norm": 2.779191017150879,
      "learning_rate": 8.247405125800038e-05,
      "loss": 0.0844,
      "step": 700
    },
    {
      "epoch": 1.0581222056631894,
      "grad_norm": 2.275271415710449,
      "learning_rate": 8.180967389862782e-05,
      "loss": 0.056,
      "step": 710
    },
    {
      "epoch": 1.0730253353204173,
      "grad_norm": 2.0460052490234375,
      "learning_rate": 8.11357243523351e-05,
      "loss": 0.0721,
      "step": 720
    },
    {
      "epoch": 1.0879284649776453,
      "grad_norm": 1.3115867376327515,
      "learning_rate": 8.045240542444023e-05,
      "loss": 0.0404,
      "step": 730
    },
    {
      "epoch": 1.1028315946348732,
      "grad_norm": 2.8956730365753174,
      "learning_rate": 7.975992273970143e-05,
      "loss": 0.0732,
      "step": 740
    },
    {
      "epoch": 1.1177347242921014,
      "grad_norm": 1.0783390998840332,
      "learning_rate": 7.905848468044033e-05,
      "loss": 0.0547,
      "step": 750
    },
    {
      "epoch": 1.1326378539493294,
      "grad_norm": 1.6027978658676147,
      "learning_rate": 7.834830232383543e-05,
      "loss": 0.0849,
      "step": 760
    },
    {
      "epoch": 1.1475409836065573,
      "grad_norm": 3.5753231048583984,
      "learning_rate": 7.762958937840468e-05,
      "loss": 0.08,
      "step": 770
    },
    {
      "epoch": 1.1624441132637853,
      "grad_norm": 2.4984054565429688,
      "learning_rate": 7.690256211969613e-05,
      "loss": 0.0831,
      "step": 780
    },
    {
      "epoch": 1.1773472429210134,
      "grad_norm": 2.2357640266418457,
      "learning_rate": 7.616743932520618e-05,
      "loss": 0.058,
      "step": 790
    },
    {
      "epoch": 1.1922503725782414,
      "grad_norm": 2.7069754600524902,
      "learning_rate": 7.542444220854485e-05,
      "loss": 0.0529,
      "step": 800
    },
    {
      "epoch": 1.2071535022354694,
      "grad_norm": 4.020897388458252,
      "learning_rate": 7.467379435286819e-05,
      "loss": 0.06,
      "step": 810
    },
    {
      "epoch": 1.2220566318926975,
      "grad_norm": 3.9284634590148926,
      "learning_rate": 7.391572164359736e-05,
      "loss": 0.071,
      "step": 820
    },
    {
      "epoch": 1.2369597615499255,
      "grad_norm": 2.757986545562744,
      "learning_rate": 7.31504522004451e-05,
      "loss": 0.0501,
      "step": 830
    },
    {
      "epoch": 1.2518628912071534,
      "grad_norm": 2.7668418884277344,
      "learning_rate": 7.23782163087698e-05,
      "loss": 0.0816,
      "step": 840
    },
    {
      "epoch": 1.2667660208643814,
      "grad_norm": 1.9815062284469604,
      "learning_rate": 7.159924635027788e-05,
      "loss": 0.0658,
      "step": 850
    },
    {
      "epoch": 1.2816691505216096,
      "grad_norm": 2.3813018798828125,
      "learning_rate": 7.081377673309538e-05,
      "loss": 0.0644,
      "step": 860
    },
    {
      "epoch": 1.2965722801788375,
      "grad_norm": 2.7496325969696045,
      "learning_rate": 7.002204382122966e-05,
      "loss": 0.0684,
      "step": 870
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 2.694636583328247,
      "learning_rate": 6.922428586344264e-05,
      "loss": 0.0923,
      "step": 880
    },
    {
      "epoch": 1.3263785394932937,
      "grad_norm": 1.3251090049743652,
      "learning_rate": 6.842074292155682e-05,
      "loss": 0.0629,
      "step": 890
    },
    {
      "epoch": 1.3412816691505216,
      "grad_norm": 1.8850162029266357,
      "learning_rate": 6.761165679821571e-05,
      "loss": 0.0864,
      "step": 900
    },
    {
      "epoch": 1.3561847988077496,
      "grad_norm": 2.6343185901641846,
      "learning_rate": 6.679727096412044e-05,
      "loss": 0.0821,
      "step": 910
    },
    {
      "epoch": 1.3710879284649775,
      "grad_norm": 2.742957353591919,
      "learning_rate": 6.597783048476441e-05,
      "loss": 0.0572,
      "step": 920
    },
    {
      "epoch": 1.3859910581222057,
      "grad_norm": 3.215703248977661,
      "learning_rate": 6.515358194668807e-05,
      "loss": 0.0599,
      "step": 930
    },
    {
      "epoch": 1.4008941877794336,
      "grad_norm": 3.4879770278930664,
      "learning_rate": 6.432477338327585e-05,
      "loss": 0.0923,
      "step": 940
    },
    {
      "epoch": 1.4157973174366618,
      "grad_norm": 4.966557025909424,
      "learning_rate": 6.349165420011784e-05,
      "loss": 0.0841,
      "step": 950
    },
    {
      "epoch": 1.4307004470938898,
      "grad_norm": 3.1400747299194336,
      "learning_rate": 6.265447509995856e-05,
      "loss": 0.0701,
      "step": 960
    },
    {
      "epoch": 1.4456035767511177,
      "grad_norm": 1.8236725330352783,
      "learning_rate": 6.181348800725526e-05,
      "loss": 0.056,
      "step": 970
    },
    {
      "epoch": 1.4605067064083457,
      "grad_norm": 2.5898642539978027,
      "learning_rate": 6.096894599236871e-05,
      "loss": 0.0654,
      "step": 980
    },
    {
      "epoch": 1.4754098360655736,
      "grad_norm": 2.783750534057617,
      "learning_rate": 6.0121103195409035e-05,
      "loss": 0.0563,
      "step": 990
    },
    {
      "epoch": 1.4903129657228018,
      "grad_norm": 3.57137393951416,
      "learning_rate": 5.927021474975979e-05,
      "loss": 0.0638,
      "step": 1000
    },
    {
      "epoch": 1.5052160953800298,
      "grad_norm": 3.366777181625366,
      "learning_rate": 5.8416536705303035e-05,
      "loss": 0.053,
      "step": 1010
    },
    {
      "epoch": 1.520119225037258,
      "grad_norm": 1.817091464996338,
      "learning_rate": 5.756032595136863e-05,
      "loss": 0.0525,
      "step": 1020
    },
    {
      "epoch": 1.535022354694486,
      "grad_norm": 2.88946795463562,
      "learning_rate": 5.670184013943097e-05,
      "loss": 0.0548,
      "step": 1030
    },
    {
      "epoch": 1.5499254843517138,
      "grad_norm": 5.183380603790283,
      "learning_rate": 5.5841337605576324e-05,
      "loss": 0.053,
      "step": 1040
    },
    {
      "epoch": 1.5648286140089418,
      "grad_norm": 3.5097877979278564,
      "learning_rate": 5.497907729276416e-05,
      "loss": 0.0695,
      "step": 1050
    },
    {
      "epoch": 1.5797317436661698,
      "grad_norm": 1.0572049617767334,
      "learning_rate": 5.41153186729059e-05,
      "loss": 0.0428,
      "step": 1060
    },
    {
      "epoch": 1.594634873323398,
      "grad_norm": 4.11565637588501,
      "learning_rate": 5.325032166878445e-05,
      "loss": 0.0869,
      "step": 1070
    },
    {
      "epoch": 1.6095380029806259,
      "grad_norm": 2.7400155067443848,
      "learning_rate": 5.238434657583808e-05,
      "loss": 0.0427,
      "step": 1080
    },
    {
      "epoch": 1.624441132637854,
      "grad_norm": 0.9713956117630005,
      "learning_rate": 5.151765398383219e-05,
      "loss": 0.0634,
      "step": 1090
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 2.9910614490509033,
      "learning_rate": 5.065050469844239e-05,
      "loss": 0.0641,
      "step": 1100
    },
    {
      "epoch": 1.65424739195231,
      "grad_norm": 1.997489333152771,
      "learning_rate": 4.9783159662772804e-05,
      "loss": 0.0615,
      "step": 1110
    },
    {
      "epoch": 1.669150521609538,
      "grad_norm": 0.7553197741508484,
      "learning_rate": 4.8915879878832807e-05,
      "loss": 0.0595,
      "step": 1120
    },
    {
      "epoch": 1.6840536512667659,
      "grad_norm": 1.239193081855774,
      "learning_rate": 4.804892632899622e-05,
      "loss": 0.0393,
      "step": 1130
    },
    {
      "epoch": 1.698956780923994,
      "grad_norm": 3.249763011932373,
      "learning_rate": 4.7182559897466243e-05,
      "loss": 0.0709,
      "step": 1140
    },
    {
      "epoch": 1.713859910581222,
      "grad_norm": 4.482987880706787,
      "learning_rate": 4.6317041291770144e-05,
      "loss": 0.0612,
      "step": 1150
    },
    {
      "epoch": 1.7287630402384502,
      "grad_norm": 3.0168495178222656,
      "learning_rate": 4.545263096430683e-05,
      "loss": 0.0754,
      "step": 1160
    },
    {
      "epoch": 1.7436661698956781,
      "grad_norm": 4.493851661682129,
      "learning_rate": 4.458958903397152e-05,
      "loss": 0.056,
      "step": 1170
    },
    {
      "epoch": 1.758569299552906,
      "grad_norm": 4.02513313293457,
      "learning_rate": 4.372817520788041e-05,
      "loss": 0.0741,
      "step": 1180
    },
    {
      "epoch": 1.773472429210134,
      "grad_norm": 4.773563385009766,
      "learning_rate": 4.286864870321965e-05,
      "loss": 0.0628,
      "step": 1190
    },
    {
      "epoch": 1.788375558867362,
      "grad_norm": 6.511744976043701,
      "learning_rate": 4.201126816924137e-05,
      "loss": 0.0604,
      "step": 1200
    },
    {
      "epoch": 1.8032786885245902,
      "grad_norm": 3.1101090908050537,
      "learning_rate": 4.115629160943095e-05,
      "loss": 0.0625,
      "step": 1210
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 1.7494393587112427,
      "learning_rate": 4.030397630386824e-05,
      "loss": 0.0759,
      "step": 1220
    },
    {
      "epoch": 1.8330849478390463,
      "grad_norm": 1.4152934551239014,
      "learning_rate": 3.9454578731806935e-05,
      "loss": 0.0516,
      "step": 1230
    },
    {
      "epoch": 1.8479880774962743,
      "grad_norm": 1.9539523124694824,
      "learning_rate": 3.860835449449443e-05,
      "loss": 0.0515,
      "step": 1240
    },
    {
      "epoch": 1.8628912071535022,
      "grad_norm": 2.7041406631469727,
      "learning_rate": 3.776555823825633e-05,
      "loss": 0.086,
      "step": 1250
    },
    {
      "epoch": 1.8777943368107302,
      "grad_norm": 2.649890899658203,
      "learning_rate": 3.692644357786798e-05,
      "loss": 0.0514,
      "step": 1260
    },
    {
      "epoch": 1.8926974664679581,
      "grad_norm": 4.127903938293457,
      "learning_rate": 3.609126302023666e-05,
      "loss": 0.0514,
      "step": 1270
    },
    {
      "epoch": 1.9076005961251863,
      "grad_norm": 2.557471752166748,
      "learning_rate": 3.526026788841692e-05,
      "loss": 0.0419,
      "step": 1280
    },
    {
      "epoch": 1.9225037257824145,
      "grad_norm": 1.882676601409912,
      "learning_rate": 3.443370824598245e-05,
      "loss": 0.0454,
      "step": 1290
    },
    {
      "epoch": 1.9374068554396424,
      "grad_norm": 3.4581499099731445,
      "learning_rate": 3.361183282177661e-05,
      "loss": 0.0421,
      "step": 1300
    },
    {
      "epoch": 1.9523099850968704,
      "grad_norm": 3.49886417388916,
      "learning_rate": 3.279488893506498e-05,
      "loss": 0.0567,
      "step": 1310
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 4.12408447265625,
      "learning_rate": 3.198312242111173e-05,
      "loss": 0.0764,
      "step": 1320
    },
    {
      "epoch": 1.9821162444113263,
      "grad_norm": 5.094208717346191,
      "learning_rate": 3.117677755720284e-05,
      "loss": 0.0916,
      "step": 1330
    },
    {
      "epoch": 1.9970193740685542,
      "grad_norm": 2.0604984760284424,
      "learning_rate": 3.0376096989137924e-05,
      "loss": 0.0491,
      "step": 1340
    },
    {
      "epoch": 2.0119225037257826,
      "grad_norm": 0.6940785646438599,
      "learning_rate": 2.9581321658213225e-05,
      "loss": 0.0124,
      "step": 1350
    },
    {
      "epoch": 2.0268256333830106,
      "grad_norm": 0.509017288684845,
      "learning_rate": 2.8792690728717243e-05,
      "loss": 0.0167,
      "step": 1360
    },
    {
      "epoch": 2.0417287630402385,
      "grad_norm": 0.17508859932422638,
      "learning_rate": 2.801044151596147e-05,
      "loss": 0.0026,
      "step": 1370
    },
    {
      "epoch": 2.0566318926974665,
      "grad_norm": 0.0795745924115181,
      "learning_rate": 2.7234809414867136e-05,
      "loss": 0.0044,
      "step": 1380
    },
    {
      "epoch": 2.0715350223546944,
      "grad_norm": 1.5962597131729126,
      "learning_rate": 2.6466027829130124e-05,
      "loss": 0.0057,
      "step": 1390
    },
    {
      "epoch": 2.0864381520119224,
      "grad_norm": 0.39582404494285583,
      "learning_rate": 2.5704328100984996e-05,
      "loss": 0.0125,
      "step": 1400
    },
    {
      "epoch": 2.1013412816691504,
      "grad_norm": 0.39157846570014954,
      "learning_rate": 2.4949939441589283e-05,
      "loss": 0.005,
      "step": 1410
    },
    {
      "epoch": 2.1162444113263787,
      "grad_norm": 0.3521392345428467,
      "learning_rate": 2.42030888620491e-05,
      "loss": 0.0026,
      "step": 1420
    },
    {
      "epoch": 2.1311475409836067,
      "grad_norm": 1.7243733406066895,
      "learning_rate": 2.346400110510696e-05,
      "loss": 0.0114,
      "step": 1430
    },
    {
      "epoch": 2.1460506706408347,
      "grad_norm": 0.28646957874298096,
      "learning_rate": 2.2732898577511853e-05,
      "loss": 0.0026,
      "step": 1440
    },
    {
      "epoch": 2.1609538002980626,
      "grad_norm": 0.6404273509979248,
      "learning_rate": 2.201000128309267e-05,
      "loss": 0.0012,
      "step": 1450
    },
    {
      "epoch": 2.1758569299552906,
      "grad_norm": 0.014388936571776867,
      "learning_rate": 2.129552675655432e-05,
      "loss": 0.0011,
      "step": 1460
    },
    {
      "epoch": 2.1907600596125185,
      "grad_norm": 0.025867927819490433,
      "learning_rate": 2.0589689998017238e-05,
      "loss": 0.0083,
      "step": 1470
    },
    {
      "epoch": 2.2056631892697465,
      "grad_norm": 0.08286966383457184,
      "learning_rate": 1.9892703408319234e-05,
      "loss": 0.0062,
      "step": 1480
    },
    {
      "epoch": 2.220566318926975,
      "grad_norm": 0.16799283027648926,
      "learning_rate": 1.9204776725099865e-05,
      "loss": 0.0046,
      "step": 1490
    },
    {
      "epoch": 2.235469448584203,
      "grad_norm": 0.0720769539475441,
      "learning_rate": 1.8526116959685913e-05,
      "loss": 0.0028,
      "step": 1500
    },
    {
      "epoch": 2.2503725782414308,
      "grad_norm": 0.41595855355262756,
      "learning_rate": 1.7856928334797513e-05,
      "loss": 0.0031,
      "step": 1510
    },
    {
      "epoch": 2.2652757078986587,
      "grad_norm": 0.020752327516674995,
      "learning_rate": 1.719741222309326e-05,
      "loss": 0.0008,
      "step": 1520
    },
    {
      "epoch": 2.2801788375558867,
      "grad_norm": 0.09606501460075378,
      "learning_rate": 1.6547767086573083e-05,
      "loss": 0.004,
      "step": 1530
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 0.18079349398612976,
      "learning_rate": 1.5908188416856835e-05,
      "loss": 0.0024,
      "step": 1540
    },
    {
      "epoch": 2.3099850968703426,
      "grad_norm": 0.042730625718832016,
      "learning_rate": 1.527886867635696e-05,
      "loss": 0.0198,
      "step": 1550
    },
    {
      "epoch": 2.3248882265275705,
      "grad_norm": 0.09889388829469681,
      "learning_rate": 1.465999724036246e-05,
      "loss": 0.0112,
      "step": 1560
    },
    {
      "epoch": 2.339791356184799,
      "grad_norm": 0.3906650245189667,
      "learning_rate": 1.4051760340052095e-05,
      "loss": 0.0009,
      "step": 1570
    },
    {
      "epoch": 2.354694485842027,
      "grad_norm": 0.0862935334444046,
      "learning_rate": 1.3454341006453435e-05,
      "loss": 0.0006,
      "step": 1580
    },
    {
      "epoch": 2.369597615499255,
      "grad_norm": 0.04500249773263931,
      "learning_rate": 1.2867919015365192e-05,
      "loss": 0.0028,
      "step": 1590
    },
    {
      "epoch": 2.384500745156483,
      "grad_norm": 2.9988460540771484,
      "learning_rate": 1.2292670833258851e-05,
      "loss": 0.0019,
      "step": 1600
    },
    {
      "epoch": 2.3994038748137108,
      "grad_norm": 0.0037489847745746374,
      "learning_rate": 1.1728769564176368e-05,
      "loss": 0.0219,
      "step": 1610
    },
    {
      "epoch": 2.4143070044709387,
      "grad_norm": 0.021559888496994972,
      "learning_rate": 1.1176384897639525e-05,
      "loss": 0.0033,
      "step": 1620
    },
    {
      "epoch": 2.429210134128167,
      "grad_norm": 0.20231297612190247,
      "learning_rate": 1.063568305758691e-05,
      "loss": 0.0011,
      "step": 1630
    },
    {
      "epoch": 2.444113263785395,
      "grad_norm": 0.5853211879730225,
      "learning_rate": 1.0106826752353621e-05,
      "loss": 0.003,
      "step": 1640
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.53504878282547,
      "learning_rate": 9.589975125709083e-06,
      "loss": 0.0122,
      "step": 1650
    },
    {
      "epoch": 2.473919523099851,
      "grad_norm": 0.11653444170951843,
      "learning_rate": 9.085283708967306e-06,
      "loss": 0.0039,
      "step": 1660
    },
    {
      "epoch": 2.488822652757079,
      "grad_norm": 1.1233909130096436,
      "learning_rate": 8.592904374184385e-06,
      "loss": 0.0028,
      "step": 1670
    },
    {
      "epoch": 2.503725782414307,
      "grad_norm": 0.08543618023395538,
      "learning_rate": 8.112985288456981e-06,
      "loss": 0.005,
      "step": 1680
    },
    {
      "epoch": 2.5186289120715353,
      "grad_norm": 0.10366899520158768,
      "learning_rate": 7.645670869335892e-06,
      "loss": 0.0022,
      "step": 1690
    },
    {
      "epoch": 2.533532041728763,
      "grad_norm": 0.6506525874137878,
      "learning_rate": 7.191101741367712e-06,
      "loss": 0.0176,
      "step": 1700
    },
    {
      "epoch": 2.548435171385991,
      "grad_norm": 0.009911811910569668,
      "learning_rate": 6.7494146937781335e-06,
      "loss": 0.0007,
      "step": 1710
    },
    {
      "epoch": 2.563338301043219,
      "grad_norm": 0.5147108435630798,
      "learning_rate": 6.320742639309118e-06,
      "loss": 0.0252,
      "step": 1720
    },
    {
      "epoch": 2.578241430700447,
      "grad_norm": 0.2880599796772003,
      "learning_rate": 5.9052145742228226e-06,
      "loss": 0.0042,
      "step": 1730
    },
    {
      "epoch": 2.593144560357675,
      "grad_norm": 0.01094493642449379,
      "learning_rate": 5.502955539483901e-06,
      "loss": 0.0061,
      "step": 1740
    },
    {
      "epoch": 2.608047690014903,
      "grad_norm": 0.10151469707489014,
      "learning_rate": 5.114086583132116e-06,
      "loss": 0.0015,
      "step": 1750
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 0.05706603825092316,
      "learning_rate": 4.738724723856469e-06,
      "loss": 0.0065,
      "step": 1760
    },
    {
      "epoch": 2.637853949329359,
      "grad_norm": 0.017409291118383408,
      "learning_rate": 4.376982915781919e-06,
      "loss": 0.0058,
      "step": 1770
    },
    {
      "epoch": 2.6527570789865873,
      "grad_norm": 0.11845500022172928,
      "learning_rate": 4.028970014479072e-06,
      "loss": 0.0006,
      "step": 1780
    },
    {
      "epoch": 2.6676602086438153,
      "grad_norm": 0.23994360864162445,
      "learning_rate": 3.694790744207377e-06,
      "loss": 0.0003,
      "step": 1790
    },
    {
      "epoch": 2.682563338301043,
      "grad_norm": 0.21180492639541626,
      "learning_rate": 3.374545666401374e-06,
      "loss": 0.0111,
      "step": 1800
    },
    {
      "epoch": 2.697466467958271,
      "grad_norm": 0.8874104022979736,
      "learning_rate": 3.068331149409742e-06,
      "loss": 0.0019,
      "step": 1810
    },
    {
      "epoch": 2.712369597615499,
      "grad_norm": 0.05592993274331093,
      "learning_rate": 2.7762393394960008e-06,
      "loss": 0.0047,
      "step": 1820
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.20901714265346527,
      "learning_rate": 2.498358133109885e-06,
      "loss": 0.0275,
      "step": 1830
    },
    {
      "epoch": 2.742175856929955,
      "grad_norm": 0.386953204870224,
      "learning_rate": 2.2347711504374204e-06,
      "loss": 0.01,
      "step": 1840
    },
    {
      "epoch": 2.7570789865871834,
      "grad_norm": 0.14861901104450226,
      "learning_rate": 1.9855577102379343e-06,
      "loss": 0.0057,
      "step": 1850
    },
    {
      "epoch": 2.7719821162444114,
      "grad_norm": 0.5873615741729736,
      "learning_rate": 1.7507928059753598e-06,
      "loss": 0.0017,
      "step": 1860
    },
    {
      "epoch": 2.7868852459016393,
      "grad_norm": 1.9170055389404297,
      "learning_rate": 1.5305470832512048e-06,
      "loss": 0.0105,
      "step": 1870
    },
    {
      "epoch": 2.8017883755588673,
      "grad_norm": 0.01841592788696289,
      "learning_rate": 1.3248868185457785e-06,
      "loss": 0.0005,
      "step": 1880
    },
    {
      "epoch": 2.8166915052160952,
      "grad_norm": 0.08322694897651672,
      "learning_rate": 1.1338738992742849e-06,
      "loss": 0.0036,
      "step": 1890
    },
    {
      "epoch": 2.8315946348733236,
      "grad_norm": 3.8568546772003174,
      "learning_rate": 9.57565805163585e-07,
      "loss": 0.004,
      "step": 1900
    },
    {
      "epoch": 2.846497764530551,
      "grad_norm": 0.9213451147079468,
      "learning_rate": 7.960155909553957e-07,
      "loss": 0.0053,
      "step": 1910
    },
    {
      "epoch": 2.8614008941877795,
      "grad_norm": 0.5158249735832214,
      "learning_rate": 6.492718704409761e-07,
      "loss": 0.0023,
      "step": 1920
    },
    {
      "epoch": 2.8763040238450075,
      "grad_norm": 0.007631537038832903,
      "learning_rate": 5.173788018322912e-07,
      "loss": 0.0003,
      "step": 1930
    },
    {
      "epoch": 2.8912071535022354,
      "grad_norm": 0.09320807456970215,
      "learning_rate": 4.003760744738405e-07,
      "loss": 0.0048,
      "step": 1940
    },
    {
      "epoch": 2.9061102831594634,
      "grad_norm": 0.15373089909553528,
      "learning_rate": 2.982988968993683e-07,
      "loss": 0.0073,
      "step": 1950
    },
    {
      "epoch": 2.9210134128166914,
      "grad_norm": 1.989670991897583,
      "learning_rate": 2.1117798623683794e-07,
      "loss": 0.0086,
      "step": 1960
    },
    {
      "epoch": 2.9359165424739198,
      "grad_norm": 0.40787866711616516,
      "learning_rate": 1.3903955896506505e-07,
      "loss": 0.0019,
      "step": 1970
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 0.06423802673816681,
      "learning_rate": 8.190532302459475e-08,
      "loss": 0.003,
      "step": 1980
    },
    {
      "epoch": 2.9657228017883757,
      "grad_norm": 0.6836634278297424,
      "learning_rate": 3.979247128536034e-08,
      "loss": 0.0097,
      "step": 1990
    },
    {
      "epoch": 2.9806259314456036,
      "grad_norm": 0.4109708368778229,
      "learning_rate": 1.2713676372988482e-08,
      "loss": 0.0157,
      "step": 2000
    },
    {
      "epoch": 2.9806259314456036,
      "eval_loss": 0.9523536562919617,
      "eval_runtime": 206.7718,
      "eval_samples_per_second": 5.765,
      "eval_steps_per_second": 5.765,
      "step": 2000
    },
    {
      "epoch": 2.9955290611028316,
      "grad_norm": 0.08959564566612244,
      "learning_rate": 6.770868553440667e-10,
      "loss": 0.0113,
      "step": 2010
    },
    {
      "epoch": 3.0,
      "step": 2013,
      "total_flos": 1.938741778933678e+17,
      "train_loss": 0.08760584968753378,
      "train_runtime": 3313.1689,
      "train_samples_per_second": 9.711,
      "train_steps_per_second": 0.608
    }
  ],
  "logging_steps": 10,
  "max_steps": 2013,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.938741778933678e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
